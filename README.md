# Behavioral Interview Categorization

## 1. Dataset Overview
### 1.1 Millennial Sentiment Interview Dataset
- **Source**: Kaggle
- **Website Link**: https://www.kaggle.com/datasets/parmarmanojkumar/msitd/data
- **Records**: 18 interview records
- **Content**: Contains behavioral interview transcripts of interviews from millennial candidates. One sheet for interviewees' answers and the other sheet for the questions asked.

### 1.2 Sales Interview Dataset
- **Source**: Kaggle
- **Website Link**: https://www.kaggle.com/datasets/suryasanju/interview-selection-dataset
- **Records**: over 20000 behavioral interview transcripts of sales scenario from candidates
- **Content**: Contains interview questions and scripted answers from applicants for a sales role, including comments, red flags, and scores rated on the interviewees.

### 1.3 Software Engineering Q&A
- **Source**: Hugging Face `juasdexter/interview_questions`
- **Website Link**: https://huggingface.co/datasets/juasdexter/interview_questions
- **Records**: 602 technical Q&A pairs
- **Content**: Contains questions and answers of technical programming interviews

### 1.4 Simulated Interview Dataset**
- **Source**: Hugging Face `â€œali-alkhars/interviews`
- **Website Link**: https://huggingface.co/datasets/SamRex39/AI-Interviewer
- **Records**: 72 simulated interview exchanges
- **Content**: Contains behavioral interview questions and answers generated by AI

## 2. Dataset Cleaning and Preprocessing
### 2.1 Dataset Cleaning
- **Text Normalization**
```python
# Text Cleaning Process
def clean_text(text):
  # Standardize formats
  # Remove whitespace
  # Remove special characters
  # Remove filler words
```
  
- **PII Removal**
```python
# Initialize AnalyzerEngine and AnonymizerEngine engines
# Anonymizer
def remove_pii(text):
  # Uses Microsoft Presidio for entity detection
```

- **Scoring Normalization**
- Converted all scores to a 1-5 scale
```python
# Normalized numerical scores schema
def normalize_scores(df, score_cols):
  # Using min and max values to normalize the scores to 1-5
```
 
### 2.2 Dataset Preprocessing
- For each dataset, apply the Text Normalization, PII Removal, and Scoring Normalization to preprocess

## 3. Competency Mapping
- Used O*NET-based framework to define a competency map
```python
COMPETENCY_MAP = {
    'communication': ['express', 'explain', 'present', 'discuss', 'communicate'],
    'teamwork': ['collaborate', 'team', 'work together', 'support', 'help', 'cooperate', 'conflict', 'partner', 'member'],
    'problem_solving': ['solve', 'resolve', 'fix', 'troubleshoot', 'issue', 'problem', 'challenge'],
    'leadership': ['lead', 'manage', 'mentor', 'guide', 'direct', 'organize']
}
```
- Map the answer with the competency if the answer mentioned words in a different competency category

## 4. STAR Component Detection
- Define STAR keywords 
```python
STAR_KEYWORDS = {
    'situation': ['when', 'situation', 'context', 'scenario', 'environment', 'during'],
    'task': ['task', 'responsibility', 'role', 'objective', 'goal', 'asked to', 'responsible for'],
    'action': ['action', 'approach', 'method', 'implement', 'utilized', 'decided', 'developed', 'explored', 'collected', 'construct', 'evaluated', 'conducted', 'identified'],
    'result': ['result', 'outcome', 'impact', 'achievement', 'conclusion', 'success']
}
```
- Map the answer with the STAR keywords to see if the answer follows the STAR principle

## 5. Question Categorization
- Used TF-IDF vectorization and K-Means clustering to identify 4 question types: Communication, Teamwork, Problem Solving, Leadership
- Cluster them into the correct groups
- Save necessary outputs
